{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANLY 580 - NLP for Data Analytics Fall Semester 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook relies on the preprocessing performed in the topic modeling using LDA notebook. The dictionary and corpus preprocessing is re-used in this notebook to demonstrate topic modeling using Non-negative Matrix Factorization (NNMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify these parmeters for the local directory structre where the data is located. \n",
    "\n",
    "data_file_path = \"data/ANLY580/data\"\n",
    "TEMP_FOLDER = \"data/ANLY580/backup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the parsed_tweets dataframe from the ldamodel\n",
    "parsed_tweets_types = {'msgid':str, 'topic':str, 'sentiment':str, 'Tweet':list}\n",
    "parsed_tweets = pd.read_csv(os.path.join(data_file_path, \"parsed_tweets.csv\"),\n",
    "                            sep=\"\\t\",\n",
    "                            index_col = 0,\n",
    "                            dtype={'msgid':str, 'topic':str, 'sentiment':str, 'Tweet':str},\n",
    "                            converters={\"Tweet\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "parsed_tweets.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tweets.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_topics = list(set(parsed_tweets['topic'].tolist()))\n",
    "print(human_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dictionary and corpus computed for the lda model.\n",
    "\n",
    "dictionary = corpora.Dictionary.load(os.path.join(TEMP_FOLDER, 'semval.dict'))  # load from dictionary\n",
    "corpus = corpora.MmCorpus(os.path.join(TEMP_FOLDER, 'semval.mm'))  # load from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In NNMF factorization we will use term-frequency-inverse_document-frequency for weighting the term document matrix\n",
    "\n",
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model\n",
    "corpus_tfidf = tfidf[corpus]      # step 2 -- use the model to transform vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the total_topics number to examine impacts the number of topics has with NNMF\n",
    "\n",
    "total_topics = 20\n",
    "num_passes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "nmf = Nmf(corpus, id2word = dictionary, passes = 20, num_topics = total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show first n=10 important words in the topics:\n",
    "nmf.show_topics(total_topics, num_words = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the topic - term data into an pyton dictionary\n",
    "data_nmf = {i: OrderedDict(nmf.show_topic(i,10)) for i in range(total_topics)}\n",
    "#data_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the ordered dictionary to load the data into a dataframe\n",
    "data_nmf = pd.DataFrame(data_nmf)\n",
    "data_nmf = data_nmf.fillna(0).T\n",
    "print(data_nmf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nmf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the original documents back thru the model to infer the distribution of topics \n",
    "# according to the nnmf model\n",
    "\n",
    "topics = []\n",
    "probs = []\n",
    "max_to_show = 20\n",
    "\n",
    "for k, i in enumerate(range(len(parsed_tweets['Tweet']))):\n",
    "    bow = dictionary.doc2bow(parsed_tweets['Tweet'][i])\n",
    "    doc_topics = nmf.get_document_topics(bow, minimum_probability = 0.01)\n",
    "    topics_sorted = sorted(doc_topics, key = lambda x: x[1], reverse = True)\n",
    "    topics.append(topics_sorted[0][0])\n",
    "    probs.append(\"{}\".format(topics_sorted[0][1]))\n",
    "    \n",
    "    # Dump out the topic and probability assignments for the first 20 documents\n",
    "    if k < max_to_show:\n",
    "        print(\"Document {}: {}\".format(k, topics_sorted))\n",
    "\n",
    "parsed_tweets['NMFtopic'] = pd.Series(topics)\n",
    "parsed_tweets['NMFprob'] = pd.Series(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the topic assignments for the last document thru the previous loop\n",
    "\n",
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resort the dataframe according to the human annotated topic and nnmf topic\n",
    "parsed_tweets.sort_values(['topic', 'NMFtopic'], ascending=[True, False], inplace=True)\n",
    "parsed_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the distributions of human annotated topics in the data via a barplot\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12.7,9.27)})\n",
    "by_topic = sns.countplot(x='NMFtopic', data=parsed_tweets)\n",
    "\n",
    "for item in by_topic.get_xticklabels():\n",
    "    item.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resort the dataframe according to the the nnmf assigned topic and the human annotated topic\n",
    "\n",
    "parsed_tweets.sort_values(['NMFtopic', 'topic'], ascending=[True, True], inplace=True)\n",
    "parsed_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resort the dataframe according to the the nnmf assigned topic and the assocoiated probability\n",
    "parsed_tweets.sort_values(['NMFtopic', 'NMFprob'], ascending=[True, False], inplace=True)\n",
    "parsed_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the topic distrubtions look like relative to the original human annotated/tagged topics\n",
    "\n",
    "df2 = parsed_tweets.groupby(['NMFtopic', 'topic'])['NMFtopic'].count().unstack('topic')\n",
    "topic_mixture = df2[human_topics].plot(kind='bar', stacked=True, legend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the topic distrubtions look like relative to the original human annotated/tagged sentiment\n",
    "\n",
    "human_sentiment = list(set(parsed_tweets['sentiment'].tolist()))\n",
    "df2 = parsed_tweets.groupby(['NMFtopic', 'sentiment'])['NMFtopic'].count().unstack('sentiment')\n",
    "topic_mixture = df2[human_sentiment].plot(kind='bar', stacked=True, legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
